services:
  workspace:
    image: mcr.microsoft.com/devcontainers/typescript-node:18
    volumes:
      - .:/workspace
      - /var/run/docker.sock:/var/run/docker.sock
    working_dir: /workspace
    command: sleep infinity

  frontend:
    build:
      context: .
      dockerfile: ./frontend/Dockerfile
    ports:
      - "3000:3000"
    environment:
      - NODE_ENV=development
      - NEXT_PUBLIC_API_URL=http://localhost:8000
      - NEXT_PUBLIC_BACKEND_URL=http://localhost:8000
      - NEXT_PUBLIC_WS_URL=ws://localhost:8000
      - NEXT_PUBLIC_VSCODE_PROXY_URL=http://localhost:8081
      - NEXT_PUBLIC_MCP_WS_URL=ws://localhost:9002
      - BACKEND_URL=http://backend:8000
      - NODE_OPTIONS=--dns-result-order=ipv4first
      - HOSTNAME=0.0.0.0
    volumes:
      - ./frontend:/app
      - ./shared:/shared
      - /app/node_modules
      - /app/.next
    depends_on:
      - backend

  backend:
    build:
      context: .
      dockerfile: ./backend/Dockerfile
    ports:
      - "8000:8000"
    extra_hosts:
      - "host.docker.internal:host-gateway"
    environment:
      - NODE_ENV=development
      - PORT=8000
      - DB_HOST=postgres
      - DB_PORT=5432
      - DB_USERNAME=postgres
      - DB_PASSWORD=password
      - DB_NAME=coding_agent
      - DB_SYNCHRONIZE=false
      - LLM_SERVICE_URL=http://llm-service:9000
      - VECTOR_DB_URL=http://qdrant:6333
      - OLLAMA_HOST=http://ollama:11434
      # API keys explicitly unset to avoid validation errors
      - OPENAI_API_KEY=
      - ANTHROPIC_API_KEY=
      - COHERE_API_KEY=
      - REDIS_URL=redis://redis:6379
      - FRONTEND_URL=http://localhost:3000
      - JWT_SECRET=${JWT_SECRET:-your_jwt_secret_key_here_make_it_long_and_secure_for_production_use_at_least_32_chars}
      - SESSION_SECRET=${SESSION_SECRET:-your_session_secret_key_here_make_it_long_and_secure_for_production_use_at_least_32_chars}
    volumes:
      - ./backend:/app
      - ./shared:/shared
      - backend_node_modules:/app/node_modules
      - .:/workspace
    command: ["npm", "run", "start:dev"]
    depends_on:
      - qdrant
      - postgres
      - redis

  llm-service:
    build:
      context: .
      dockerfile: ./llm-service/Dockerfile
    ports:
      - "9000:9000"
    extra_hosts:
      - "host.docker.internal:host-gateway"
    environment:
      - NODE_ENV=development
      - OLLAMA_HOST=http://ollama:11434
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
      - HUGGINGFACE_API_KEY=${HUGGINGFACE_API_KEY}
      - MODEL_CACHE_DIR=/models/cache
      - REDIS_URL=redis://redis:6379
    volumes:
      - ./llm-service:/app
      - ./shared:/shared
      - ./models:/models
      - /app/node_modules
    depends_on:
      - redis

  qdrant:
    image: qdrant/qdrant:latest
    platform: linux/amd64
    ports:
      - "6333:6333"
    volumes:
      - ./qdrant_data:/qdrant_data
    environment:
      - QDRANT__SERVICE__HTTP_PORT=6333

  ollama:
    image: ollama/ollama:latest
    platform: linux/amd64
    ports:
      - "11434:11434"
    volumes:
      - ./ollama_data:/root/.ollama
    environment:
      - OLLAMA_ORIGINS=*
      - OLLAMA_HOST=0.0.0.0
      - OLLAMA_NUM_PARALLEL=1
      - OLLAMA_MAX_LOADED_MODELS=1
    runtime: runc

  vscode:
    image: codercom/code-server:latest
    platform: linux/amd64
    ports:
      - "8080:8080"
    environment:
      - SHELL=/bin/bash
      - DISABLE_WORKSPACE_TRUST=true
    volumes:
      - .:/home/coder/workspace
    command: >
      --bind-addr 0.0.0.0:8080
      --auth none
      --disable-telemetry
      --disable-update-check
      --disable-workspace-trust
      --disable-file-downloads
      --disable-getting-started-override
      /home/coder/workspace

  vscode-proxy:
    build:
      context: ./vscode-proxy
      dockerfile: Dockerfile
    ports:
      - "8081:8081"
    environment:
      - NODE_ENV=development
      - VSCODE_PROXY_PORT=8081
      - VSCODE_URL=http://vscode:8080
      - JWT_SECRET=${JWT_SECRET:-your_jwt_secret_key_here_make_it_long_and_secure_for_production_use_at_least_32_chars}
      - FRONTEND_URL=${FRONTEND_URL:-http://localhost:3000}
      - REQUIRE_AUTH=false
    depends_on:
      - vscode

  mcp-server:
    build:
      context: .
      dockerfile: ./mcp-server/Dockerfile
    ports:
      - "9001:9001"
      - "9002:9002"
    environment:
      - NODE_ENV=development
      - MCP_PORT=9001
      - VSCODE_HOST=vscode
      - VSCODE_PORT=8080
      - LLM_SERVICE_URL=http://llm-service:9000
      - BACKEND_URL=http://backend:8000
    volumes:
      - .:/workspace
    depends_on:
      - vscode
      - backend
      - llm-service

  postgres:
    image: postgres:15
    platform: linux/amd64
    ports:
      - "5432:5432"
    environment:
      - POSTGRES_DB=coding_agent
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=password
    volumes:
      - ./postgres_data:/var/lib/postgresql/data

  redis:
    image: redis:7-alpine
    platform: linux/amd64
    ports:
      - "6379:6379"
    volumes:
      - ./redis_data:/data

volumes:
  backend_node_modules:
  vscode-extensions:
  vscode-data:

networks:
  default:
    name: coding-agent-network